---
title: "Base Model"
date: "Updated on : `r date()`"
output: html_document
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## 0. Objective

This notebook aims to demonstrate the following steps to help find nutrition predictors that associate with diastolic blood pressure.
We will run the a OLS model with linear compare with the linear model with spline function apply on the continuous variables; further, we show the QA/QC process to choose baseline

![work](process.png){width=80%}

## Step 1. Identify Data

We are using the [National Health and Nutrition Examination Survey ï¼ˆNHANES)](https://www.cdc.gov/nchs/nhanes/index.htm) datasets to  NHANES are collected from the Centers for Disease Control and Prevention in the USA, including demographics, dietary, laboratory, examination, and questionnaire data. 

The survey is carried out in two year "epochs" from 1999-2000 to 2017-2018, and that within an epoch a set of people are surveyed. However, not all of the participants are surveyed for all of the components (e.g. demographics, dietary, laboratory, examination, and questionnaire) of the survey.  

Each participant is assigned a unique ID and that is stored in the database as \texttt{SEQN} which is then used as a primary key. Any merging of data extracted from different tables should be based on \texttt{SEQN}. 
Within each of the two-year epochs NHANES has produced a set of tables, or data files. One example is the [Body Measures](https://wwwn.cdc.gov/nchs/nhanes/2001-2002/BMX_B.htm)
table, which provides data from the 2001-2002 surveys.

In this notebook, we will use the following data across over years.
 - [Demographics Data](https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&CycleBeginYear=2015)
 - Examination Data( [Body Measures](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BMX_I.htm)[Blood Pressure](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm)]
 - Dietary Data [Dietary Interview - Total Nutrient Intakes, First Day(https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1TOT_I.htm)] 


## Step 2. Identify a response and a set of confounders that will be adjusted for.

#### 1 ) Identify a response, or outcome of interest.
In this demonstration, we averaged the first and second read of diastolic blood pressure as the response, and more details can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/BPX_I.htm#BPXDI1).

#### 2 ) Identify a set of confounders that will be adjusted for.  These are typically not of interest themselves, but are important established confounders such as age or sex that should be adjusted for.

We choose,gender, age, ethnicity and education from Demographics Data, and BMI from Body Measure as the confounders that will be adjusted for blood pressure.


## Step 3 Load data and preprocess along with PHESEANT

setup database configuration

```{r setup,warning=FALSE,message=FALSE}
library(EnWAS)
library(splines)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(DBI)
library(phonto)
library(DT)

# setup database configuration
sqlHost <- "localhost"
sqlUserName <- "sa"
sqlPassword <- "yourStrong(!)Password"
sqlDefaultDb <- "NhanesLandingZone"
```


#### 1) Load and check with PHESANT-like

More data query and search tools can be found on [quick start page](https://ccb-hms.github.io/Imputation/6_phonto/quick_start.html).

```{r pre}
cols = c("RIDAGEYR","RIAGENDR","BMXBMI","RIDRETH1","DMDEDUC2","years",'BPXDI1','BPXDI2')
base_df = jointQuery(c('BodyMeasures','DemographicVariablesAndSampleWeights','BloodPressure'),cols)
phs_res = phesant(base_df)
DT::datatable(phs_res$phs_res)
```
In the above, the PHESANT-like function provides the ratio of unique values (`r_unique`), the proportion of zeros (`r_zeros`), and the ratio of NAs (`r_NAs`), which is calculated by the number of unique values, zeros, and NAs divided by total records. The categorical data types (ordered or unrecorded) are presented by integers, and the PHESANT function category them as multilevel. For example, education (DMDEDUC2) is category as Multilevel(7) means the PHESANT process considers it multilevel and has 7 levels.


We remove missing values (NAs) in data. Also, we removed blood pressure filled with 0 because 0 values present dead people which does not make sense.

The gender(`RIAGENDR`) and ethnicity (`RIDRETH1`) are converted to categorical variables.


```{r}
# remove age under 20 and diastolic with 0s
base_df = base_df |> subset(RIDAGEYR>20 & BPXDI1!=0 & BPXDI2!=0 )

# assign the gender and ethnicity to the real levels
base_df = nhanesA::nhanesTranslate('DEMO_I', c('RIAGENDR', 'RIDRETH1'), data=base_df)

# Transform education to:
#  < High School
#   - High School
#  > High School
nDEDUC = ifelse(base_df$DMDEDUC2 < 3, "<HS", ifelse(base_df$DMDEDUC2 == 3, "HS", 
                                                    ifelse(base_df$DMDEDUC2 < 6, ">HS", NA)))
base_df$DMDEDUC2 <- as.factor(nDEDUC)

base_df = na.omit(base_df)

# Take average first and second read for the diastolic blood pressure.
base_df$DIASTOLIC <- (base_df$BPXDI1+base_df$BPXDI2)/2


```

## 3.2 Build Baseline Model


In the following demonstrations, we built a linear model and a spline model to show that spline models outperform the linear when we have continuous variables. The outcome is diastolic is the average of the diastolic first (`BPXDI1`) and second (`BPXDI2`) reads, gender(`RIAGENDR`), age (`RIDAGEYR`), ethnicity (`RIDRETH1`), BMI(`BMXBMI`) and the ratio of family income to poverty (`INDFMPIR`)


 Although the knots can be set with percentiles or with the degree of freedom, we manually set the knots because we want the knots fixed when we run EnWAS to compare the impacts of the phenotypes fairly.  We set age knots from 30 to 80 by 10s and boundary knots as (20, 90) because the age range is about 22 to 85. Increasing the number of knots may not hurt the model's performance when the data size is relatively large, but it is better to set fewer knots in ranges with fewer data points. We need to set the knots when the data distribution is skewed carefully. As the BMI distribution is considerably skewed, data points larger than 45 are much less than those in the range of 15-45. Therefore, we set knots for BMI as 15 to 45 by 5s and 45 to 65  by 10s, and boundary knots as (10, 85). Note that boundary knots are required when the knots are manually set; otherwise, the models may raise errors when the knots are out of the data range. 


```{r build_base_model}

lm_str <- 'DIASTOLIC ~ RIDAGEYR*RIAGENDR + BMXBMI + RIDRETH1+DMDEDUC2+years'
lm_base <- lm(formula = as.formula(lm_str),base_df)

ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1+DMDEDUC2+years'
ns_base <- lm(formula = as.formula(ns_str), base_df)

sjPlot::tab_model(lm_base,ns_base,
                  dv.labels = c("OLS", "OLS+Spline"),
                  show.ci = FALSE,show.stat = TRUE,show.se = TRUE)
```




## 4. QA/QC for Base Model

We need to check the base model and ensure it runs correctly before performing EnWAS. However, the classical methods such as Q-Q plots, residual plots, and goodness of fit (GoF) tests are generally ill-suited. For example, we can plot residuals against fitted values with smoothed scatter plot, as follows. We do not find any noticeable trends for none of the models; even the spline outperforms the linear model.



#### 4.1 Residual vs. Fitted Value

We can check the residuals against the fitted value with a smooth scatter plot. And we find that there are no apparent trends for both models, even though the spline model has fewer mean square errors.

```{r residual_ft,results = "asis",fig.width = 8,fig.height=4,dpi=200}
# par(mfrow = c(1, 2))
layout(matrix(c(1,2), ncol=2, byrow=TRUE))
par(mar=c(4.0,4.0,3.5,1))
smoothScatter(lm_base$fitted.values,lm_base$residuals,xlab="Fitted Values",ylab ="Residuals",main = "Linear Model")
lines(lowess(lm_base$fitted.values,lm_base$residuals),lwd=3,col="red")
smoothScatter(ns_base$fitted.values,ns_base$residuals,
              colramp = colorRampPalette(c("white", "yellow3")),
              xlab="Fitted Values",ylab ="Residuals",main = "Spline Model")
lines(lowess(ns_base$fitted.values,ns_base$residuals),lwd=3,col="black")

```

#### 4.2 Residuals vs. Terms

A possible solution to check the "goodness of fit (GoF)" is to check whether apparent trends in the plots of residual against terms in the models. We can spot a slight trend residual in the BMI range from 20 to 40, indicating that using linear regression on BMI term may not hurt the model performance too much. However, a strong parabola-like trend can be observed in the residuals of the linear model with respect to ages, which indicates that the linear model cannot capture age. In other words, the model is not good enough to be a base model to run EnWAS; the findings are more likely false positives if using such a base model. On the other hand, the residuals spline model has no clear trends with respect to both BMI and age, which means the base model captures the relations of outcomes (diastolic) and the known confounders.


```{r residual,results = "asis",dpi=200}
layout(matrix(c(1,2), ncol=2, byrow=TRUE))
par(mar=c(4.0,4.0,3.5,1))
smoothScatter(base_df$RIDAGEYR,lm_base$residuals,xlab="Age (Years)",ylab ="residuals",main = "Linear Model")
lines(lowess(base_df$RIDAGEYR,lm_base$residuals),lwd=3,col="red")
smoothScatter(base_df$RIDAGEYR,ns_base$residuals,xlab="Age (Years)",
              colramp = colorRampPalette(c("white", "yellow3")),
              ylab ="residuals",main = "Spline Model")
lines(lowess(base_df$RIDAGEYR,ns_base$residuals),lwd=3,col="black")

```

#### 4.2 Binned Plots
We can further check the base models with binned plots, which can be helpful when the data set is large. The binned plot is a way that "zoom in" to look at the treends.

```{r residualbin,results = "asis"}
df_age_res <- list("Linear"=make_bins(x=base_df$RIDAGEYR,y=lm_base$residual,nbin=1000),
                "Spline"=make_bins(x=base_df$RIDAGEYR,y=ns_base$residuals,nbin=1000)
                )
age_res <- plot_bins2(df_age_res,xlab="Age (year)",ylab="Binned Residuals") + ylim(-8,6.5)
age_res

```

```{r binned33,results = "asis",warning=FALSE,fig.width = 10,fig.height=10,dpi=200}


# Residuals vs. Fitted Values
pred_df <- data.frame("Age"=base_df$RIDAGEYR, 
                      "Gender"=base_df$RIAGENDR,
                      "BMI"=base_df$BMXBMI,
                      "DIASTOLIC" = base_df$DIASTOLIC,
                      "Linear"=lm_base$fitted.values,
                      "Spline"=ns_base$fitted.values)



mpred_df <- reshape::melt(pred_df, id=c("DIASTOLIC","Age","Gender",'BMI'))

base_raw_g <- ggplot(mpred_df,
         aes(
           x = Age,
           y = DIASTOLIC
         )) +
  geom_point(data = ~ group_by(.x, Age, Gender,BMI) |> sample_frac(0.2),
             alpha = 0.2, shape=1) +
  geom_smooth(aes(x = Age,y=value,colour=variable),size=1.5,
              method='lm',formula=y ~ splines::ns(x,df=7)
              )+
  xlab("Age (year)")+ylab("Diastolic (mmHg)")+ facet_grid(cols = vars(variable))+
   scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
  theme_minimal()



pred_df <- data.frame("Age"=base_df$RIDAGEYR, "Gender"=base_df$RIAGENDR, "BMI"=base_df$BMXBMI,"DIASTOLIC" = base_df$DIASTOLIC,"Linear"=lm_base$residuals,"Spline"=ns_base$residuals)



mpred_df <- reshape::melt(pred_df, id=c("DIASTOLIC","Age","Gender",'BMI'))
res_g <- ggplot(
    mpred_df, aes(x = Age, y = value)) +
    stat_density2d(aes(fill = ..density..^0.25), 
                   geom = "tile", contour = FALSE, n = 200) +  
  geom_smooth(aes(x = Age,y=value,colour=variable),
              size=1.5,method='lm',formula=y ~ splines::ns(x,df=7))+
  facet_grid(cols = vars(variable))+scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
    viridis::scale_fill_viridis(guide="none",option = "A",alpha = 0.6) +
  ylab("Residuals")+ xlab("Age(year)")+
  theme_minimal() 



tmp_df <- data.frame(Fitted_Value = c(lm_base$fitted.values,ns_base$fitted.values),
                     Residuals = c(lm_base$residuals,ns_base$residuals),
                     model = c(rep("Linear",nrow(base_df)),rep("Spline",nrow(base_df)))
                     )
fitt_g <- ggplot(tmp_df, aes(x = Fitted_Value, y = Residuals)) +
    stat_density2d(aes(fill = ..density..^0.25),
                   geom = "tile", contour = FALSE, n = 200) +
  geom_smooth(aes(x = Fitted_Value, y = Residuals,colour=model),
              size=1.5,method='lm',formula=y ~ splines::ns(x,df=7))+
  facet_grid(cols = vars(model))+
  scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
  xlab("Fitted Values")+
    scale_fill_viridis_c(alpha = 0.6,guide = "none") + theme_minimal()



```

- <em><strong> a) </strong></em> The yellow and blue lines are generated by smooth prediction from linear and spline models. The dots are randomly sampled in 20% of the data points.
- <em><strong> b) </strong></em> Smooth scatter plots for residuals with respect to fitted values, and there is no strong pattern in both cases even though the spline has less mean square error than the linear model.
- <em><strong> c) </strong></em> Smooth scatter plots for residuals with respect to age variable,  and the linear model has a parabola-like pattern, whereas no obvious pattern for the spline model.
- <em><strong> d) </strong></em> Binned plots for residuals with respect to age variable to look at the trends of residuals against age.

```{r BPXDI12, echo=TRUE,warning=FALSE,message=FALSE, fig.width = 10,fig.height=10}
ggpubr::ggarrange(base_raw_g,fitt_g,res_g,age_res,nrow = 4,ncol = 1,labels = c('a)','b)','c)','d)'))
```

## Step 5 Identify a set of phenotypes and exposures 

Identify a set of phenotypes and exposures that we want to test for association with the response variable of interest.

In this example, we choose phenotype from the dietary data, we identified the phenotypes and saved them into a built-in variable call `exposure_vars` in EnWAS package. More detail of the phenotypes can be found [here](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DR1TOT_I.htm).

```{r}
diet_data = unionQuery('DietaryInterviewTotalNutrientIntakesFirstDay',exposure_vars)
```
#### 1) Transformation
In NHANES, the phenotypes are often right-skewed with a very long tail on the right side of the distribution, which can be addressed with logarithm transformation followed by a z-transformation. However, it would take a tremendous effort to manually and exhaustively inspect the distributions and figure out appropriate transformation methods for all kinds of phenotypes with different types of distribution when dealing with extensive data sets. Therefore, we recommend using inverse normal transformation (INT) for all continuous variables because INT can apply various distributions. We compared the EnWAS results of logarithm transformation followed by a z-transformation with normal inverse transformation. 

Here is an example of DR1TTFAT - Total fat (gm).

```{r}
plot_trans <- function(x){
  layout(matrix(c(1,2,3), ncol=3, byrow=TRUE))
  par(mar=c(4.0,4.0,3.5,1))
  x <- na.omit(x)
  hist(x,main = "none")
  log(x+1e-5) |> scale() |> hist(main="log-Z")
  invNorm(x) |> hist(main="INVT")  
}
plot_trans(diet_data$DR1TTFAT)
```
Another example is DR1TMOIS - Moisture (gm).
```{r}
plot_trans(diet_data$DR1TMOIS)
```
Generally, INT can do better job than the scale and log method in the above cases.


## Step 6 Carry out a set of regression models
In this step, we need to carry out a set of regression models, one for each exposure/phenotype in Step 5, and report on the analysis.

```{r}
data = merge(base_df,diet_data,by = "SEQN")
data = na.omit(data)
xwas = enwas(ns_str,exposure_vars,data)
xwas_log <- enwas(ns_str,exposure_vars,data,trans = "log")
xwas_inv <- enwas(ns_str,exposure_vars,data,trans = "inv")
```

The following forest plot shows the estimates and CI of the exposure variables and only displays the top 30 (if they have more than 30 satisfy the filters) ranked by absolute values of the estimates. The variables with their CI containing zeros are also removed.

```{r enwas00_forest, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
forest_plot(xwas$enwas_res,30) # filter out CI contains 0
```




The following forest plot shows the top 20 exposures, ranked by the differences in the estimates for the same variables.
- `ns` denotes the variables non-transformed, but the estimates  with beta^hat * SD(X)
- `ns_inv` denotes variables transformed inverse normal transformation
- `ns-log` denotes variables transformed with log followed by z-transformation

```{r enwas_inv1log, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
forest_plot_mult(list(ns=xwas$enwas_res,ns_inv=xwas_inv$enwas_res,ns_log=xwas_log$enwas_res),20)
```

The following scatter plot shows the inverse normal transformation estimates against estimates (beta^hat * SD(X)) of nontransformed variables. The top 20 has added text for the variables, but it is pretty clear to show the information.

```{r enwas_inv22, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
ns=xwas$enwas_res
ns_inv=xwas_inv$enwas_res
ns_log=xwas_log$enwas_res
enwas_res = data.frame(x=ns$estimate,
                       x_upper = ns$upper,
                       x_lower = ns$lower,
                       y=ns_inv$estimate,
                       y_upper=ns_inv$upper,
                       y_lower=ns_inv$lower,
                       z=ns_log$estimate,
                       z_upper=ns_log$upper,
                       z_lower=ns_log$lower,
                       diff1 = abs(ns_inv$estimate-ns$estimate),
                       diff2 = abs(ns_log$estimate-ns$estimate),
                       diff3 = abs(ns_log$estimate-ns_inv$estimate),
                       term = ns_inv$term
                       )
```

The following scatter plot remove the error bars and text labeled the top 20 most difference variables.

Scatter plot for estimates of EnWAS  non-transformed (`EnWAS`) with inverse normal transformation (`EnWAS INT`).
```{r enwas_inv230, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
library(ggrepel)

top_n_diff <- 20
enwas_res |>
ggplot(aes(x,y,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(x,y,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff1),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS") + ylab("EnWAS INT")
```

Scatter plot for estimates of EnWAS  non-transformed (`EnWAS`) with log and z-transformation (`EnWAS Log`).

```{r enwas_inv231, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
enwas_res |>
ggplot(aes(x,z,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(x,z,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff1),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS") + ylab("EnWAS Log")
```

Scatter plot for estimates of EnWAS inverse normal transformation (`EnWAS INT`) with log and z-transformation (`EnWAS Log`).

```{r enwas_inv232, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
enwas_res |>
ggplot(aes(y,z,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(y,z,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff3),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS INT") + ylab("EnWAS Log")

```




