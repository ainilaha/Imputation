---
title: "EnWAS Base Model: Diasatolic-Blood Pressure"
date: "Updated on : `r date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Load libs and Load data
The process of load libs and data is the same as [EnWAS sample](https://ccb-hms.github.io/Imputation/7_enwas/EnWAS_simple.html).

```{r data, warning=FALSE,message=FALSE,echo=FALSE}
# source("../6_nhanes_data/phesant.R")

library(DBI)
# library(broom)
library(splines)
# library(stringr)
library(dplyr)
library(ggplot2)
library(EnWAS)
library(Hmisc)

exposure_vars <-
  read.delim("../../data/select_vars.txt", header = FALSE)$V1
exposure_cols <- paste(exposure_vars, collapse = ", ")


# Load data and convert data types according to PHESEANT.
# Return data set and PHESEANT results.
load_data <- function(exposure_cols) {
  nhanes_db <- dbConnect(RSQLite::SQLite(), "../../nhanes.sqlite")

  
  cols <-
    'SEQN,BMXWAIST, RIDAGEYR, BMXHT, BMXBMI, BMXWT, RIAGENDR,SDMVPSU,SDMVSTRA,RIDRETH1, INDFMPIR, years,'
  data_sql <-
    paste('SELECT', cols, exposure_cols, 'FROM merged_table')
  
  data <- dbGetQuery(nhanes_db, data_sql)
  data <- na.omit(data)
  dbDisconnect(nhanes_db)
  
  data
  
}

nhanes_data <- load_data(exposure_cols) 
data_phs <- phesant(nhanes_data)

data <- data_phs$data
phs_res <- data_phs$phs_types



```

## Query Extra data 
This part loads the blood pressure data and merges it with the dietary and demographic data in the above section.

```{r query, echo=TRUE}
set.seed(123)
nhanes_db <- dbConnect(RSQLite::SQLite(), "../../nhanes.sqlite")
# BPXDI2,BPXSY1
blood_pressure <- dbGetQuery(nhanes_db, "select SEQN, BPXDI1,BPXDI2 from BloodPressure where BPXDI1 IS NOT NULL and BPXDI1 <> 0 and BPXDI2 IS NOT NULL and BPXDI2 <> 0")

dbDisconnect(nhanes_db)
blood_pressure$diastolic <- rowMeans(blood_pressure[, c('BPXDI1','BPXDI2')])


data <- merge(blood_pressure, data, by = "SEQN")
data <- data[sample(1:nrow(data)), ] # shuffle the data
data$years <- as.factor(data$years)
ethnicity <-
  c(
    'Mexican American',
    'Other Hispanic',
    'Non-Hispanic White',
    'Non-Hispanic Black',
    'Other Race'
  )

levels(data$RIDRETH1) <- ethnicity
```

## Base Model

```{r func3, echo=TRUE,warning=F, out.width = '90%'}
lm_str <- 'diastolic ~ RIDAGEYR*RIAGENDR + BMXBMI + RIDRETH1'
lm_base <- lm(as.formula(lm_str), data)

ns_str <-
  'diastolic ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base <- lm(as.formula(ns_str), data)
```

## Bins plot functions


```{r plot_functions, echo=TRUE,warning=FALSE,message=FALSE,results = "asis"}
library(ggpubr)
library(reshape)

plot_bins<- function(x,y,xlab="Value",ylab="Binned Residuals",title="linear",nbin=600){

  df <- make_bins(x,y,nbin)
  g <- ggplot(df,aes(breaks,mean)) + geom_point() +
  geom_errorbar(aes(ymin=y_min,ymax=y_max))+
  geom_smooth(aes(breaks,mean),method = "lm", formula = y ~  ns(x, df=7))+
  ylab(ylab) + xlab(xlab) + labs(title = title)

 g

}



```


## Diastolic: Blood pres (1st rdg) mm Hg

This section compares linear and spline regression of Diastolic blood pressure against age and BMI.

```{r BPXDI1, echo=TRUE,warning=FALSE}

pred_df <- data.frame("Age"=data$RIDAGEYR,
                      "Gender"=data$RIAGENDR,
                      "BMI"=data$BMXBMI,
                      "Linear"=lm_base$fitted.values,
                      "Spline"=ns_base$fitted.values)



mpred_df <- reshape::melt(pred_df, id=c("Age","Gender",'BMI'))

fit_bmi <- ggplot(mpred_df, aes(x=BMI, y=value,colour=Gender) ) +
 geom_smooth() + geom_point(data = ~ group_by(.x, Age, Gender,variable) |> sample_frac(0.05),alpha=0.2)+
  facet_grid(cols = vars(variable))+ ylab("Fitted Values")+ xlab("BMI (kg/m²)")+
  theme_minimal()

fit_age <- ggplot(mpred_df, aes(x=Age, y=value,colour=Gender) ) +
 geom_smooth() + geom_point(data = ~ group_by(.x, Age, Gender,variable) |> sample_frac(0.05),alpha=0.2)+
  facet_grid(cols = vars(variable))+ylab("Fitted Values")+ xlab("Age (year)")+
  theme_minimal()


df_bmi_res <- list("Linear"=make_bins(x=data$BMXBMI,lm_base$residuals,nbin=600),
                "Spline"=make_bins(x=data$BMXBMI,y=ns_base$residuals,nbin=600)
                )

df_age_res <- list("Linear"=make_bins(x=data$RIDAGEYR,y=lm_base$residual,nbin=600),
                "Spline"=make_bins(x=data$RIDAGEYR,y=ns_base$residuals,nbin=600)
                )





bmi_res <- plot_bins2(df_bmi_res,xlab="BMI (kg/m²)",ylab="Binned Residuals")+ ylim(-8,6.5) + xlim(min(data$BMXBMI),max(data$BMXBMI))
age_res <- plot_bins2(df_age_res,xlab="Age (year)",ylab="Binned Residuals") + ylim(-8,6.5)



raw_age <- ggplot(data,
         aes(
           x = RIDAGEYR,
           y = diastolic
         )) +
  geom_point(data = ~ group_by(.x, RIDAGEYR, RIAGENDR,BMXBMI) |> sample_frac(0.5),
             alpha = 0.2, shape=1) + 
  geom_smooth(method = "lm",formula = y~x, aes(colour="Linear"),size=1.5)+
  geom_smooth(method = "lm",formula = y~ns(x,df=7),aes(colour="Spline"),size=1.5) +
  labs(colour="Gender")+
  xlab("Age (year)")+ylab("Diastolic (mm Hg)")+
   scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
  theme_minimal()

raw_bmi <- ggplot(data,
     aes(
           x = BMXBMI,
           y = diastolic
        )) +
  geom_point(data = ~ group_by(.x, RIDAGEYR, RIAGENDR,BMXBMI) |> sample_frac(0.5),
             aes(fill=RIAGENDR),
             alpha = 0.2, shape=21) + 
  geom_smooth(method = "lm",formula = y~x, aes(colour="Linear"),size=1.5)+
  geom_smooth(method = "lm",formula = y~ns(x,df=7),aes(colour="Spline"),size=1.5) +
  xlab("BMI (kg/m²)")+ylab("Diastolic (mm Hg)")+
  # scale_fill_manual(values = c("#009E73", "#F0E442"))+
  scale_colour_manual(values=c("#E69F00", "#56B4E9"))+
  theme_minimal()+
  labs(fill="Gender", colour="Model")

# ggpubr::ggarrange(raw_bmi,raw_age,bmi_res,age_res,common.legend = TRUE,labels = c('a','b','c','d'))


```

- <em><strong> a) </strong></em> and <em><strong> b) </strong></em> are the raw data with smooth fitted lines.

- <em><strong> c) </strong></em> and <em><strong> d) </strong></em> show fitted values of linear and spline regression against the BMI ($km/m^2$) and Age (years) colored by the gender of the participants. The lines show the relation between fitted values with BMI. For visibility, we sampled 5% of data with transparency (alpha=0.2) on the image.


- <em><strong> e) </strong></em> and <em><strong> f) </strong></em> show binned residuals against the BMI ($km/m^2$) and Age (years) colored by the models (linear and spline regression). The values on x-axis (BMI and Age) are binned, and each bin contains about 600 data points; further the mean of residuals are plotted with error bar ([$-1.96 \sqrt{\sigma_r},1.96\sqrt{\sigma_r}]$), where $\sqrt{\sigma_r}$ is the standard deviation of residuals in the bins. The binned residual can stretch the data point out so that it shows clear patterns of the residuals in each bin.

- <em><strong> c) </strong></em> and <em><strong> e) </strong></em> show that diastolic blood pressure does not have a strictly linear relation with BMI. The binned residuals of linear regression show a pattern, whereas there is no obvious trend or pattern for the spline regression because the spline model fits the non-linearity relations.

- <em><strong> d) </strong></em> and <em><strong> f) </strong></em> show that the linear regression model has a significant residual overall, performing even worse for participants younger than 30 and older than 70. Therefore, applying linear regression could miss leading in EnWAS analysis.  Residuals of the linear regression against age have an apparent trend (parabola-like shape), and residuals of spline regression have no apparent tendency. In other words, the non-linear relationship was not explained by linear regression and was left out in the residuals.



```{r BPXDI12, echo=TRUE,warning=FALSE,message=FALSE, fig.width = 10,fig.height=10}
raw_g <- ggpubr::ggarrange(raw_bmi,raw_age,
                           common.legend = TRUE,
                           labels = c('a)','b)'),legend='right')

fit_g <- ggpubr::ggarrange(fit_bmi, fit_age,
                           common.legend = TRUE,
                           labels = c('c)','d)'),legend='right')


res_g <- ggpubr::ggarrange(bmi_res,age_res,common.legend = TRUE,labels = c('e)','f)'),legend='right')


ggpubr::ggarrange(raw_g,fit_g,res_g,nrow = 3,ncol = 1)
```

- <em><strong> Note: The trends are difficult to see in binned residuals plot with BMI because most data are squeezed in a small range. A possible solution is to separate BMI from age plots </strong></em> 




## Cross-Validation to determe number of Knots for Age

The matrix of the mean square errors (MSE) and standard deviations of choosing different knots show that the changing number of quantile knots or specific integer knots do not significantly impact the model. Although hold-on different years data set as validation data makes the performance slightly different, increasing the number of age knots does not significantly impact the model performance. The main reason is that the data diastolic has a quadratic (parabola-like), which only requires three knots to reach the goal, and more data knots will not help. More knots may hurt the performance when we have a relatively small amount of data. Still, it does not compromise the performance because we have enough data to prevent the model from overfitting by introducing too many knots.

```{r cv, echo=TRUE,warning=FALSE,message=FALSE}
qs <- 5:22

cross_validation <- function(q_list=qs,base_model=ns_str,df=data) {
  len_q <- length(q_list)
  
  
  # leave out 2011-2012 because max age in the years is 80, which lead some issue to set up knots
  # as above
  # https://stat.ethz.ch/pipermail/r-devel/2011-May/061035.html
  
  years <- levels(df$years)
  
  len_year <- length(years)
  
  mse_mtx <- matrix(0, nrow = len_q+1, ncol = len_year)
  rownames(mse_mtx) <- c(c(q_list - 2),"ns_base")
  colnames(mse_mtx) <- years
  
  for (i in 1:len_q) {
    # number of knots = q - 2
    q <- q_list[i]
    for (j in 1:len_year) {
      # print(years[j])
      cv_train <- df[df$years != years[j], ]
      cv_test <- df[df$years == years[j], ]
      
      knots <- quantile(unique(cv_train$RIDAGEYR), 1:(q - 2) / (q - 1),names=FALSE)
      
      knots <- paste0(knots, collapse = ', ')
      ns_model <-
        paste0(
          'diastolic ~ ns(RIDAGEYR, knots = c(',
          knots,
          '),Boundary.knots=c(20,90))* RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,80))'
        )
   
      
      cv_ns_model <- NA
      tryCatch({
        cv_ns_model <- lm(as.formula(ns_model), cv_train)

      },
      error = function(e) {
            print(paste0("years=",years[j],"raise errors:NA/NaN/Inf in foreign function call (arg 1)"))
            # print(ns_model)
          },
      finally = {
        mse_mtx[i, j] = NA
        }
      )
      if(is.list(cv_ns_model)){
        pred_vals <- predict(cv_ns_model, cv_test)
        mse_mtx[i, j] <- mean((pred_vals - cv_test$diastolic) ^ 2)
      }

    }
    
  }

  for (j in 1:len_year) {
      cv_train <- df[df$years != years[j], ]
      cv_test <- df[df$years == years[j], ]
      ns_model <- NA
      tryCatch({
        ns_model <- lm(as.formula(base_model), cv_train)

      },
      error = function(e) {
                print(paste0("years=",years[j],"raise errors:NA/NaN/Inf in foreign function call (arg 1)"))
          },
      finally = {
        mse_mtx[len_q+1, j] = NA
        }
      )
      if(is.list(ns_model)){
        pred_vals <- predict(ns_model, cv_test)
        mse_mtx[len_q+1, j] <- mean((pred_vals - cv_test$diastolic) ^ 2)
      }

    }

  mse_mtx
}

mse_mtx <- cross_validation()

knitr::kable(mse_mtx)
mse_df <- as.data.frame(reshape2::melt(mse_mtx))
colnames(mse_df) <- c("Knots","Years","MSE")

mse_df[mse_df$Knots=="ns_base",]$Knots = 6
mse_df$Knots <- as.numeric(as.character(mse_df$Knots))
mse_df |> subset(!is.na(MSE)) |> 
  ggplot(aes(Knots,MSE,color=Years)) + geom_line() + geom_point()

```





## Cross-Validation to Linear vs Spline


```{r cv2, echo=TRUE,warning=FALSE,message=FALSE}

cv_models <- function(model_list,df=data) {

  years <- levels(df$years)
  
  len_year <- length(years)
  
  mse_mtx <- matrix(0, nrow = len_year, ncol = length(model_list))
  rownames(mse_mtx) <- years
  colnames(mse_mtx) <- names(model_list)
  
 

  for (i in 1:len_year) {
      for(j in 1:length(model_list)){
      cv_train <- df[df$years != years[i], ]
      cv_test <- df[df$years == years[i], ]
      # print(model_list[j])
      ns_model <- lm(as.formula(model_list[j]), cv_train)

      pred_vals <- predict(ns_model, cv_test)
      mse_mtx[i,j] <- mean((pred_vals - cv_test$diastolic) ^ 2)
      

    }
}


  mse_mtx
}

model_list <- c(lm_str,ns_str)
names(model_list) <- c("linear","spline")
mse_mtx <- cv_models(model_list,data)

knitr::kable(mse_mtx)
mse_df <- as.data.frame(reshape2::melt(mse_mtx))
colnames(mse_df) <- c('years','model','MSE')

len_year <- length(levels(mse_df$years))
```

We can compare the model by check the residuals after running the regression. Further, we can confirm the model by using cross-validation. For example, we can compare the linear regression and spline regression with cross-validation, and the results show that spline model has much less errors.

```{r cv21, echo=TRUE,warning=FALSE,message=FALSE}
mse_df |> ggplot(aes(x=as.numeric(years),y=MSE,color=model)) +
  geom_point(size=2)+ geom_line()+
  scale_x_continuous(breaks=seq(1,len_year,1),labels=levels(mse_df$years),
                     guide = guide_axis(angle = 45))+ xlab("Years")+
  theme_minimal()

```


## ANOVA LRT (Likelihood Ratio Test)

Linear regression can be considered a special case of spline regression because spline can be a straight line. In other words, linear regression is a sub-model of spline regression in our case. Therefore, we can use ANOVA LRT to test whether the spline regression outperforms the linear regression. The spline regression has 23 more degrees of freedom than linear regression, and it reduces the residual sum of squares (RSS) from $4338763$ down to $3913906$, which is about $9.8\%$. $Pr(>Chi) < < 0.001$ may not be meaningful as we have a considerably large amount of data, making the variability small.


```{r anova1, echo=TRUE,results = "asis"}
print_anova <- function(anov_obj){
  for (a in attr(anov_obj,"heading")){
    cat(gsub(pattern = "\n", replacement = "  \n", x = a))
    }
  anov_df <- as.data.frame(anov_obj)
  anov_df <- round(anov_df,3)
  anov_df[!is.na(anov_df[,'Pr(>Chi)']) & anov_df[,'Pr(>Chi)'] <= 0.001, 'Pr(>Chi)'] <- "< 0.001"
  anov_df[is.na(anov_df)] <- ""
  
  knitr::kable(anov_df)
}
print_anova(anova(lm_base,ns_base,test="LRT"))
```



## Ethnicity and Years

```{r enthic, echo=TRUE,results = "asis"}

lm_no_race <- lm(diastolic ~ RIDAGEYR*RIAGENDR + BMXBMI, data)
lm_years <- lm(as.formula(paste0(lm_str," + years")), data)

ns_str_no_race <-
  'diastolic ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85))'


ns_no_race <- lm(ns_str_no_race, data)
ns_years <- lm(as.formula(paste0(ns_str," + years")), data)

```

Ethnicity can improve the model slightly, reducing RSS by about 0.6%~0.7%. The Non-Hispanic Black and Other Race have bigger differences than Mexican American; Other Hispanic and Non-Hispanic White do not change too much.  The correct way to contact EnWAS analysis include the ethnicity into the adjust variables. However, we leave out ethnicity variable for now so that we show the principles more simple and direct manner.

```{r enthic1, echo=TRUE,results = "asis"}
print_anova(anova(lm_no_race,lm_base,test="LRT"))
sjPlot::tab_model(lm_no_race,lm_base,
                  dv.labels = c("lm_no_race", "lm_base"),
                  show.stat=TRUE,show.dev=TRUE)
print_anova(anova(ns_no_race,ns_base,test="LRT"))
sjPlot::tab_model(ns_no_race,ns_base,
                  dv.labels = c("ns_no_race", "ns_base"),
                  show.stat=TRUE,show.dev=TRUE)
```
Including years reduce the RSS only by 0.48%, which is pretty tiny. Only the year 2017-2018 is different from the year 2003-2004 with an estimator of 1.786 and a p-value of 5.19e-10, and the rest of the years are not significantly different from 2003-2004; therefore, the years factor are excluded from the base models.

```{r years, echo=TRUE,results = "asis"}
print_anova(anova(ns_base,ns_years,test="LRT"))
sjPlot::tab_model(ns_base,ns_years,
                  dv.labels = c("lm_base", "ns_years"),
                  show.stat=TRUE,show.dev=TRUE)
```



## More Residual Plots

```{r residual122, echo=TRUE,warning=FALSE,message=FALSE,results = "asis",dpi = 200}
lm_bmi <- plot_bins(data$BMXBMI, lm_base$residuals,xlab="BMI(kg/m²)",nbin=300)
ns_bmi <- plot_bins(data$BMXBMI, ns_base$residuals,xlab="BMI(kg/m²)",title="spline",nbin=300)
lm_age <- plot_bins(data$RIDAGEYR, lm_base$residuals,xlab="Age",nbin=300)
ns_age <- plot_bins(data$RIDAGEYR, ns_base$residuals,xlab="Age",title="spline",nbin=300)

ggarrange(lm_age,ns_age,lm_bmi,ns_bmi,ncol = 2,nrow = 2,common.legend = TRUE)

```






