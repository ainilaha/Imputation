---
title: "Environment-Wide Association Study (EnWAS)"
date: "Updated on : `r date()`"
output: html_document
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## 0. Pepare for EnWAS

Details can check the previous vignette page.

```{r setup,warning=FALSE,message=FALSE}
library(EnWAS)
library(splines)
library(ggplot2)
library(ggpubr)
library(dplyr)
# data("nhanes")
# data("exposure_vars")
# phesant_res <- phesant(nhanes)
# nhanes <- phesant_res$data

library(DBI)
library(phonto)

```

## 1. Run EnWAS

```{r data_config,warning=FALSE,message=FALSE}
sqlHost <- "localhost"
sqlUserName <- "sa"
sqlPassword <- "yourStrong(!)Password"
sqlDefaultDb <- "NhanesLandingZone"
```

### 1.1 Data Preprocess with PHESANT-like tool before EnWAS
Before feeding the data into any model, we probably need to do data preprocess (e.g., clean or fill NAs, drop out columns, and transformation). In the data preprocessing phase, it is essential to properly tidy the data that models can process and learn from the data distributions; as said, “garbage in, garbage out.”  In other words, the outputs of the models may be meaningless if we feed the raw data without tidiness and with too much noise or too little information.

However, it requires a lot of effort to preprocess the data when we have large data sets with thousands of phenotype to check.
For NHANES data, we developed a PHESANT-like tool that can preprocess the data, and it can help convert the data into suitable data types. 

***We may need to discuss how we allow users to configure the tables and prototypes, json file seems OK.***


The following function takes data for the base model merge with the phenotype data configured JSON file and queries from the base. Further, we can  EnWAS function to run EnWAS on the phenotypes.
```{r enwas00, echo=TRUE,warning=F, message=FALSE,out.width = '90%',dpi = 200}


cols = c("RIDAGEYR","RIAGENDR","BMXBMI","RIDRETH1","DMDEDUC2","years")
# we can find the table name by the search function and do joint query like:
base_df = jointQuery(c('BodyMeasures','DemographicVariablesAndSampleWeights'),cols)

bpx = searchTableByName("BPX[_]")  # it would match table like BPX_, and void like BPXO_J
knitr::kable(head(bpx))

bpx_df = unionQuery(bpx$TableName,c('BPXDI1','BPXDI2'))
base_df = merge(base_df,bpx_df,by="SEQN")


base_df = base_df |> subset(RIDAGEYR>20 & BPXDI1!=0 & BPXDI2!=0 )

# The following code can be implement 
# nhanesTranslate('DEMO_D', c('RIAGENDR', 'RIDRETH1'), data=base_df)
# but it is too slow. So, I manually set the factors before we replicate the function.
base_df$RIAGENDR <- as.factor(base_df$RIAGENDR)
levels(base_df$RIAGENDR) <- c("Male","Female")
base_df$RIDRETH1 <- as.factor(base_df$RIDRETH1)
levels(base_df$RIDRETH1) <- c('Mexican American','Mexican American','Non-Hispanic White','Non-Hispanic Black','Other Race - Including Multi-Racial')
nDEDUC = ifelse(base_df$DMDEDUC2 < 3, "<HS", ifelse(base_df$DMDEDUC2 == 3, "HS", 
                                                    ifelse(base_df$DMDEDUC2 < 6, ">HS", NA)))
base_df$nDEDUC <- as.factor(nDEDUC)
base_df <-  base_df[!is.na(base_df$nDEDUC),]
base_df = na.omit(base_df)

# Take average first and second read for the diastolic blood pressure.
base_df$DIASTOLIC <- (base_df$BPXDI1+base_df$BPXDI2)/2

```

### 2.0 EnWAS

```{r enwas, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,75)) + RIDRETH1 + DMDEDUC2+years'


# For the Diet
diet_tbs = searchTablesByVar("DR1TNUMF")
diet_tbs

# The above search shows all the tables for Dietary Interview - Total Nutrient Intakes, First Day
# so, we can get the data union query
diet_data = unionQuery(diet_tbs$TableName,exposure_vars)
diet_data = na.omit(diet_data)

# run PHESANT-like function
phs_data = phesant(diet_data)
phs_data$phs_types

diet_data <- phs_data$data

data = merge(base_df,diet_data,by = "SEQN")

xwas = enwas(ns_str,exposure_vars,data)

```


The following forest plot shows the estimates and CI of the exposure variables and only displays the top 30 (if they have more than 30 satisfy the filters) ranked by absolute values of the estimates. The variables with their CI containing zeros are also removed.

```{r enwas00_forest, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
forest_plot(xwas$enwas_res,30) # filter out CI contains 0
```
#### 2.1 Phytoestrogens Urine


```{r enwas00_Phytoestrogens, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
searchTablesByVar("URXDAZ")
searchTablesByVar("URXDMA")
phy_urine = c("URXDAZ","URXDMA","URXEQU", "URXETD","URXETL","URXGNS")

# another new function that allow users query data by a group variables
phy_urine_df = queryByVars(phy_urine)

data = merge(base_df,phy_urine_df,by = "SEQN")

phyu_xwas <- enwas(ns_str,phy_urine,data)

```


#### 2.2 Phthalates Urine


```{r enwas00_Phthalates, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
knitr::kable(searchTablesByVar('URXMBP'))
# need make sure all of the variables are existing in all the tables
pht_urine <- c("URXMBP","URXMEP","URXMHP","URXMNP","URXMZP")
pht_urine_df = queryByVars(pht_urine)

data = merge(base_df,pht_urine_df,by = "SEQN")

phtu_xwas <- enwas(ns_str,pht_urine,data)
phtu_xwas_log <- enwas(ns_str,pht_urine,data,trans = "log")
phtu_xwas_inv <- enwas(ns_str,pht_urine,data,trans = "inv")

```


### 3. Inverse Normal Transformation

In addition, the EnWAS model can use inverse normal transformation on the wide association variables, which would be helpful to improve the models' performance when the distributions are skewed.

$$
\operatorname{INT}\left(W_{i}\right)=\Phi^{-1}\left\{\frac{\operatorname{rank}\left(W_{i}\right)-c}{n+1-2 c}\right\}, c \in[0,1 / 2]
$$ where c=3/8 is recommended.

The following forest plot shows the top 30 exposures, ranked and filtered as abovementioned.
```{r enwas_inv, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
data = merge(base_df,diet_data,by = "SEQN")
xwas_inv <- enwas(ns_str,exposure_vars,data,trans = "inv")
# forest_plot(xwas_inv$enwas_res,30)
```

### 4. Log and Z-transformation

The phenotype are transformed with log and z-standardized.

The following forest plot shows the top 30 exposures, ranked and filtered as abovementioned.
```{r enwas_inv1, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
xwas_log <- enwas(ns_str,exposure_vars,data,trans = "log")
# forest_plot(xwas_log$enwas_res,30)
```



The following forest plot shows the top 20 exposures, ranked by the differences in the estimates for the same variables.
- `ns` denotes the variables non-transformed, but the estimates  with beta^hat * SD(X)
- `ns_inv` denotes variables transformed inverse normal transformation
- `ns-log` denotes variables transformed with log followed by z-transformation

```{r enwas_inv1log, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
ns = rbind(xwas$enwas_res, phtu_xwas$enwas_res)
ns_inv = rbind(xwas_inv$enwas_res,phtu_xwas_inv$enwas_res)
ns_log = rbind(xwas_log$enwas_res,phtu_xwas_log$enwas_res)
forest_plot_mult(list(ns=ns,ns_inv=ns_inv,ns_log=ns_log),20)
```

The following scatter plot shows the inverse normal transformation estimates against estimates (beta^hat * SD(X)) of nontransformed variables. The top 20 has added text for the variables, but it is pretty clear to show the information.

```{r enwas_inv22, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
enwas_res = data.frame(x=ns$estimate,
                       x_upper = ns$upper,
                       x_lower = ns$lower,
                       y=ns_inv$estimate,
                       y_upper=ns_inv$upper,
                       y_lower=ns_inv$lower,
                       z=ns_log$estimate,
                       z_upper=ns_log$upper,
                       z_lower=ns_log$lower,
                       diff1 = abs(ns_inv$estimate-ns$estimate),
                       diff2 = abs(ns_log$estimate-ns$estimate),
                       diff3 = abs(ns_log$estimate-ns_inv$estimate),
                       term = ns_inv$term
                       )




```

The following scatter plot remove the error bars and text labeled the top 20 most difference variables.

Scatter plot for estimates of EnWAS  non-transformed (`EnWAS`) with inverse normal transformation (`EnWAS INT`).
```{r enwas_inv230, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
library(ggrepel)

top_n_diff <- 20
enwas_res |>
ggplot(aes(x,y,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(x,y,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff1),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS") + ylab("EnWAS INT")
```

Scatter plot for estimates of EnWAS  non-transformed (`EnWAS`) with log and z-transformation (`EnWAS Log`).

```{r enwas_inv231, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
enwas_res |>
ggplot(aes(x,z,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(x,z,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff1),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS") + ylab("EnWAS Log")
```

Scatter plot for estimates of EnWAS inverse normal transformation (`EnWAS INT`) with log and z-transformation (`EnWAS Log`).

```{r enwas_inv232, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
enwas_res |>
ggplot(aes(y,z,label = term,colour=term)) +
  geom_point(size=1.5)+
  geom_smooth(aes(y,z,colour=NULL),method = "lm", formula = y~x)+
  geom_text_repel(data=dplyr::top_n(enwas_res,top_n_diff,diff3),aes(label=term))+
  theme_minimal()+
  theme(legend.position = "none")+xlab("EnWAS INT") + ylab("EnWAS Log")

```


### 3.1 Likelihood Ratio Test: Inverse Normal Transformation to None transformd

It is still very clear to me to do the Likelihood Ratio Test because they are not nested; therefore, ANOVA LRT does not apply here. On the other hand, the vuongtest `nonnest2::vuongtest(,nested=FALSE)` produces very strange LRstat. 


```{r enwas_inv2, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
library(knitr)
library(kableExtra)

terms <- xwas$enwas_res$term
lrt_mtx <- matrix(0, nrow = length(terms), ncol = 3)
colnames(lrt_mtx) <- c("term","LRTstat","P_value")
lrt_mtx[,1] <- terms

for (i in 1:length(terms)){
  term <- terms[i]
  non_trans_model <- xwas$model_list[term][[1]]
  inv_model <- xwas_inv$model_list[term][[1]]
  vong <- nonnest2::vuongtest(non_trans_model,inv_model,nested = TRUE)
  lrt_mtx[i,2] <- round(vong$LRTstat,3)
  lrt_mtx[i,3] <- round(vong$p_LRT$A,4)
}

lrt_mtx <- as.data.frame(lrt_mtx)

lrt_mtx |> dplyr::arrange(P_value) |> head(10) |>
  kbl() |> kable_classic_2(full_width = F)

```






### 4. P-Value or FDR

```{r p_vales, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
plot_p(list(ns = ns,  ns_inv = ns_inv))
```

### 5. QA/QC

```{r aic, echo=TRUE,warning=F, message=FALSE,out.width = '90%',dpi = 200}


ns |> filter(lower*upper > 0) |>
    dplyr::top_n(30,abs(estimate)) |>
   dplyr::arrange(dplyr::desc(estimate)) |> 
  kbl() |> kable_classic_2(full_width = F)

ns |> filter(lower*upper > 0) |>
    dplyr::top_n(30,abs(estimate)) |>
   dplyr::arrange(dplyr::desc(estimate)) |> 
  kbl() |> kable_classic_2(full_width = F)







```

### 6. AC/QC plots

```{r lrt, echo=TRUE,warning=F, out.width = '90%',dpi = 200}
# lollipop(qc_mtx,y="Deviance")
# lollipop(qc_mtx,y="Ratio") + ylab("Ratio(%)")
# lollipop(qc_mtx,y="LR")
# lollipop(qc_mtx,y="p_LRT",is_desc = TRUE)
# lollipop(qc_mtx,y="BIC",is_desc = TRUE)
# lollipop(qc_mtx,y="AIC",is_desc = TRUE)
```
