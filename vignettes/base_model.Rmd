---
title: "Base Model"
date: "Updated on : `r date()`"
output: html_document
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## 1. Load libs

```{r setup,warning=FALSE,message=FALSE}
library(EnWAS)
library(splines)
library(ggplot2)
library(ggpubr)
library(dplyr)
```

## 2. Loaded data

### 2.1 Load data for the base model

We averaged two reads of diastolic blood pressures(`(BPXDI1+BPXDI2)/2 AS DIASTOLIC` ) along with confounders gender(`RIAGENDR`), age (`RIDAGEYR`), ethnicity (`RIDRETH1`), BMI(`BMXBMI`) and the ratio of family income to poverty (`INDFMPIR`) presents socioeconomic status (SES).

We removed the blood pressure filled with 0, and NAs in the data. The gender(`RIAGENDR`) and ethnicity (`RIDRETH1`) are converted to categorical variables.

```{r pre}

library(DBI)
nhanes_db <- DBI::dbConnect(RSQLite::SQLite(), "../nhanes.sqlite")

base_df <- dbGetQuery(nhanes_db, "SELECT demo.SEQN,
                                    (BPXDI1+BPXDI2)/2 AS DIASTOLIC,
                                    RIAGENDR,RIDAGEYR,RIDRETH1,BMXBMI, 
                                    INDFMPIR,DMDEDUC2
                                  FROM
                                    DemographicVariablesAndSampleWeights as demo
                                  INNER JOIN BodyMeasures
                                  ON demo.SEQN=BodyMeasures.SEQN
                                  INNER JOIN BloodPressure ON
                                  demo.SEQN=BloodPressure.SEQN
                                  WHERE
                                      RIDAGEYR>20
                                    AND BMXBMI is not NULL
                                    AND BPXDI1 IS NOT NULL and BPXDI1 <> 0
                                    AND BPXDI2 IS NOT NULL and BPXDI2 <> 0
                       ")
base_df$RIDRETH1 <- as.factor(base_df$RIDRETH1)
base_df$RIAGENDR <- as.factor(base_df$RIAGENDR)

years <- dbGetQuery(nhanes_db, "SELECT SEQN, years from demo")
base_df <- merge(base_df,years, by="SEQN")
base_df$years <- as.factor(base_df$year)
dbDisconnect(nhanes_db)
```



## 3. Identify Confonders and Build Base Model
Given the scientific question, we can identify a response or outcome of interest and covariates in the base models. 

The interaction terms of BMI and sex have a low p-value and seem meaningful to add the variable. However, adding interaction terms of BMI and sex changed the estimate of interaction terms of age and sex, making the model not change too much in general. ANOVA LRT results also show that the 'Sum of Sq' is also considerably small.


```{r basemode1}

lm_str0 <- 'DIASTOLIC ~ RIDAGEYR*RIAGENDR + BMXBMI + RIDRETH1'
lm_base0 <- lm(formula = as.formula(lm_str0),base_df)
lm_str1 <- 'DIASTOLIC ~ (RIDAGEYR+ BMXBMI)*RIAGENDR + RIDRETH1'
lm_base1 <- lm(formula = as.formula(lm_str1),base_df)
sjPlot::tab_model(lm_base0,lm_base1,
                  dv.labels = c("DIASTOLIC~Age*Sex+...", "DIASTOLIC~(Age+BMI)*Sex+..."),
                  show.stat=TRUE)
print_anova(anova(lm_base0,lm_base1,test="LRT"))
```

As we can see from the long table, none of the degrees of BMI with natural spline terms has a low p-value (< 0.05), and the 'Sum of Sq' is also considerably small. Therefore, it may not be worth adding an interaction term for the spline model.

```{r basemode10}
ns_str0 <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base0 <- lm(formula = as.formula(ns_str0),base_df)
ns_str1 <-
  'DIASTOLIC ~ (ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)))*RIAGENDR + RIDRETH1'
ns_base1 <- lm(formula = as.formula(ns_str1),base_df)
sjPlot::tab_model(ns_base0,ns_base1,
                  dv.labels = c("DIASTOLIC~ns(Age..)*Sex+...", "DIASTOLIC~((ns(Age..)+ns(BMI..))*Sex+..."),
                  show.stat=TRUE)
print_anova(anova(ns_base0,ns_base1,test="LRT"))

```



### 3.1 Check socioeconomic status (SES) and years impacts

The ratio of family income to poverty (`INDFMPIR`) has reasonable distribution in the range of 0 to 4.99 but has a peak at 5 because 5 represents the values greater than or equal to 5.00. There is no clear pattern in the smooth scatter plot of diastolic and INDFMPIR.

The p-value shows the `INDFMPIR` does not significantly impact the outcome; the estimate(-0.04) is also tiny.

We can also check the impacts of SES with ANOVA LRT. Sum of Sq = 0.82174/4517943=1.818837e-07, which indicates contribution is almost nothing. In addition, we may have to remove some of the data records where INDFMPIR values are NA. Therefore, INDFMPIR may not be worth including the base model.

```{r ses_in}

ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base <- lm(formula = as.formula(ns_str), base_df[!is.na(base_df$INDFMPIR),])


ns_str_in <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1+ INDFMPIR'
ns_base_in <- lm(formula = as.formula(ns_str_in), base_df[!is.na(base_df$INDFMPIR),])
# print_anova(anova(ns_base,ns_base_in,test="LRT"))
sjPlot::tab_model(ns_base,ns_base_in,
                  dv.labels = c("ns_base", "ns_base + INDFMPIR"),
                  show.stat=TRUE)

```

[Education](https://wwwn.cdc.gov/Nchs/Nhanes/2015-2016/DEMO_I.htm#DMDEDUC2)

The code and Value Description as following:
- 1:Less than 9th grade	
- 2:9-11th grade (Includes 12th grade with no diploma)
- 3:High school graduate/GED or equivalent		
- 4:Some college or AA degree		
- 5:College graduate or above	
- 7:Refused	
- 9:Don't Know	
- .:Missing	

Education significantly impacts the outcome (diastolic) based on p-values. However, we can find the relative Sum of Sq for `DMDEDUC2` is 1880.9/4953590=0.0003797044=0.4%, which is also considerably small.

```{r ses_edu}
base_df$DMDEDUC2 <- as.factor(base_df$DMDEDUC2)
ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base <- lm(formula = as.formula(ns_str), base_df[!is.na(base_df$DMDEDUC2),])

ns_str_edu <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1+ DMDEDUC2'
ns_base_edu <- lm(formula = as.formula(ns_str_edu), base_df[!is.na(base_df$DMDEDUC2),])

print_anova(anova(ns_base,ns_base_edu,test="LRT"))
sjPlot::tab_model(ns_base,ns_base_edu,
                  dv.labels = c("ns_base", "ns_base + DMDEDUC2"),
                  show.stat=TRUE)
```

Similar to education, years significantly impacts the outcome (diastolic) based on p-values. However, we can find the relative Sum of Sq for `year` is 47599/4953655=0.009608865= 1%, which is also considerably small.
```{r ses_year}

ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base <- lm(formula = as.formula(ns_str), base_df)

ns_str_edu <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1+ years'
ns_base_year <- lm(formula = as.formula(ns_str_edu), base_df)

print_anova(anova(ns_base,ns_base_year,test="LRT"))
sjPlot::tab_model(ns_base,ns_base_year,
                  dv.labels = c("ns_base", "ns_base + years"),
                  show.stat=TRUE)
```






## 3.2 Build Base Model


In the following demonstrations, we built a linear model and a spline model to show that spline models outperform the linear when we have continuous variables. The outcome is diastolic is the average of the diastolic first (`BPXDI1`) and second (`BPXDI2`) reads, gender(`RIAGENDR`), age (`RIDAGEYR`), ethnicity (`RIDRETH1`), BMI(`BMXBMI`) and the ratio of family income to poverty (`INDFMPIR`)


 Although the knots can be set with percentiles or with the degree of freedom, we manually set the knots because we want the knots fixed when we run EnWAS to compare the impacts of the phenotypes fairly.  We set age knots from 30 to 80 by 10s and boundary knots as (20, 90) because the age range is about 22 to 85. Increasing the number of knots may not hurt the model's performance when the data size is relatively large, but it is better to set fewer knots in ranges with fewer data points. We need to set the knots when the data distribution is skewed carefully. As the BMI distribution is considerably skewed, data points larger than 45 are much less than those in the range of 15-45. Therefore, we set knots for BMI as 15 to 45 by 5s and 45 to 65  by 10s, and boundary knots as (10, 85). Note that boundary knots are required when the knots are manually set; otherwise, the models may raise errors when the knots are out of the data range. 


```{r build_base_model}
lm_str <- 'DIASTOLIC ~ RIDAGEYR*RIAGENDR + BMXBMI + RIDRETH1'
lm_base <- lm(formula = as.formula(lm_str),base_df)

ns_str <-
  'DIASTOLIC ~ ns(RIDAGEYR, knots = seq(30, 80, by = 10), Boundary.knots=c(20,90)) * RIAGENDR + ns(BMXBMI,knots = c(seq(15, 45, by = 5),seq(45,65,by=10)),Boundary.knots=c(10,85)) + RIDRETH1'
ns_base <- lm(formula = as.formula(ns_str), base_df)
```









## 4. QA/QC for Base Model

We need to check the base model and ensure it runs correctly before performing EnWAS. However, the classical methods such as Q-Q plots, residual plots, and goodness of fit (GoF) tests are generally ill-suited. For example, we can plot residuals against fitted values with smoothed scatter plot, as follows. We do not find any noticeable trends for none of the models; even the spline outperforms the linear model.



## 4.1 Residual vs. Fitted Value

We can check the residuals against the fitted value with a smooth scatter plot. And we find that there are no apparent trends for both models, even though the spline model has fewer mean square errors.

```{r residual_ft,results = "asis",fig.width = 8,fig.height=4,dpi=200}
# par(mfrow = c(1, 2))
layout(matrix(c(1,2), ncol=2, byrow=TRUE))
par(mar=c(4.0,4.0,3.5,1))
smoothScatter(lm_base$fitted.values,lm_base$residuals,xlab="Fitted Values",ylab ="Residuals",main = "Linear Model")
lines(lowess(lm_base$fitted.values,lm_base$residuals),lwd=3,col="red")
smoothScatter(ns_base$fitted.values,ns_base$residuals,
              colramp = colorRampPalette(c("white", "yellow3")),
              xlab="Fitted Values",ylab ="Residuals",main = "Spline Model")
lines(lowess(ns_base$fitted.values,ns_base$residuals),lwd=3,col="black")

```

### 4.2 Residuals vs. Terms

A possible solution to check the "goodness of fit (GoF)" is to check whether apparent trends in the plots of residual against terms in the models. We can spot a slight trend residual in the BMI range from 20 to 40, indicating that using linear regression on BMI term may not hurt the model performance too much. However, a strong parabola-like trend can be observed in the residuals of the linear model with respect to ages, which indicates that the linear model cannot capture age. In other words, the model is not good enough to be a base model to run EnWAS; the findings are more likely false positives if using such a base model. On the other hand, the residuals spline model has no clear trends with respect to both BMI and age, which means the base model captures the relations of outcomes (diastolic) and the known confounders.


```{r residual,results = "asis",dpi=200}
# layout(matrix(c(1,2,3,4), ncol=2, byrow=TRUE))
# par(mar=c(4.0,4.0,2.5,2))

layout(matrix(c(1,2), ncol=2, byrow=TRUE))
par(mar=c(4.0,4.0,3.5,1))
smoothScatter(base_df$RIDAGEYR,lm_base$residuals,xlab="Age (Years)",ylab ="residuals",main = "Linear Model")
lines(lowess(base_df$RIDAGEYR,lm_base$residuals),lwd=3,col="red")
smoothScatter(base_df$RIDAGEYR,ns_base$residuals,xlab="Age (Years)",
              colramp = colorRampPalette(c("white", "yellow3")),
              ylab ="residuals",main = "Spline Model")
lines(lowess(base_df$RIDAGEYR,ns_base$residuals),lwd=3,col="black")

```

### 4.2 Binned Plots
We can further check the base models with binned plots, which can be helpful when the data set is large. The binned plot is a way that "zoom in" to look at the treends.

```{r residualbin,results = "asis"}
df_age_res <- list("Linear"=make_bins(x=base_df$RIDAGEYR,y=lm_base$residual,nbin=1000),
                "Spline"=make_bins(x=base_df$RIDAGEYR,y=ns_base$residuals,nbin=1000)
                )
age_res <- plot_bins2(df_age_res,xlab="Age (year)",ylab="Binned Residuals") + ylim(-8,6.5)
age_res

```

```{r binned33,results = "asis",warning=FALSE,fig.width = 10,fig.height=10,dpi=200}


# Residuals vs. Fitted Values
pred_df <- data.frame("Age"=base_df$RIDAGEYR, 
                      "Gender"=base_df$RIAGENDR,
                      "BMI"=base_df$BMXBMI,
                      "DIASTOLIC" = base_df$DIASTOLIC,
                      "Linear"=lm_base$fitted.values,
                      "Spline"=ns_base$fitted.values)



mpred_df <- reshape::melt(pred_df, id=c("DIASTOLIC","Age","Gender",'BMI'))

base_raw_g <- ggplot(mpred_df,
         aes(
           x = Age,
           y = DIASTOLIC
         )) +
  geom_point(data = ~ group_by(.x, Age, Gender,BMI) |> sample_frac(0.2),
             alpha = 0.2, shape=1) +
  geom_smooth(aes(x = Age,y=value,colour=variable),size=1.5,
              method='lm',formula=y ~ splines::ns(x,df=7)
              )+
  xlab("Age (year)")+ylab("Diastolic (mmHg)")+ facet_grid(cols = vars(variable))+
   scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
  theme_minimal()



pred_df <- data.frame("Age"=base_df$RIDAGEYR, "Gender"=base_df$RIAGENDR, "BMI"=base_df$BMXBMI,"DIASTOLIC" = base_df$DIASTOLIC,"Linear"=lm_base$residuals,"Spline"=ns_base$residuals)



mpred_df <- reshape::melt(pred_df, id=c("DIASTOLIC","Age","Gender",'BMI'))
res_g <- ggplot(
    mpred_df, aes(x = Age, y = value)) +
    stat_density2d(aes(fill = ..density..^0.25), 
                   geom = "tile", contour = FALSE, n = 200) +  
  geom_smooth(aes(x = Age,y=value,colour=variable),
              size=1.5,method='lm',formula=y ~ splines::ns(x,df=7))+
  facet_grid(cols = vars(variable))+scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
    viridis::scale_fill_viridis(guide="none",option = "A",alpha = 0.6) +
  ylab("Residuals")+ xlab("Age(year)")+
  theme_minimal() 



tmp_df <- data.frame(Fitted_Value = c(lm_base$fitted.values,ns_base$fitted.values),
                     Residuals = c(lm_base$residuals,ns_base$residuals),
                     model = c(rep("Linear",nrow(base_df)),rep("Spline",nrow(base_df)))
                     )
fitt_g <- ggplot(tmp_df, aes(x = Fitted_Value, y = Residuals)) +
    stat_density2d(aes(fill = ..density..^0.25),
                   geom = "tile", contour = FALSE, n = 200) +
  geom_smooth(aes(x = Fitted_Value, y = Residuals,colour=model),
              size=1.5,method='lm',formula=y ~ splines::ns(x,df=7))+
  facet_grid(cols = vars(model))+
  scale_colour_manual(name="Model", values=c("#E69F00", "#56B4E9"))+
  xlab("Fitted Values")+
    scale_fill_viridis_c(alpha = 0.6,guide = "none") + theme_minimal()



```

- <em><strong> a) </strong></em> The yellow and blue lines are generated by smooth prediction from linear and spline models. The dots are randomly sampled in 20% of the data points.
- <em><strong> b) </strong></em> Smooth scatter plots for residuals with respect to fitted values, and there is no strong pattern in both cases even though the spline has less mean square error than the linear model.
- <em><strong> c) </strong></em> Smooth scatter plots for residuals with respect to age variable,  and the linear model has a parabola-like pattern, whereas no obvious pattern for the spline model.
- <em><strong> d) </strong></em> Binned plots for residuals with respect to age variable to look at the trends of residuals against age.

```{r BPXDI12, echo=TRUE,warning=FALSE,message=FALSE, fig.width = 10,fig.height=10}

ggpubr::ggarrange(base_raw_g,fitt_g,res_g,age_res,nrow = 4,ncol = 1,labels = c('a)','b)','c)','d)'))
```


### 4.3 Cross Validation


Cross-Validation to Linear vs Spline


```{r cv2, echo=TRUE,warning=FALSE,message=FALSE}
model_list <- c(lm_str,ns_str)
names(model_list) <- c("linear","spline")
mse_mtx <- cv_base_m(model_list,label="DIASTOLIC",group_col="years",df=base_df)
# knitr::kable(mse_mtx)
mse_df <- as.data.frame(reshape2::melt(mse_mtx))
colnames(mse_df) <- c('years','model','MSE')
len_year <- length(levels(mse_df$years))
```

We can compare the model by check the residuals after running the regression. Further, we can confirm the model by using cross-validation. For example, we can compare the linear regression and spline regression with cross-validation, and the results show that spline model has much less errors.

```{r cv21, echo=TRUE,warning=FALSE,message=FALSE}
mse_df |> ggplot(aes(x=as.numeric(years),y=MSE,color=model)) +
  geom_point(size=5)+ geom_line(linetype = "dashed")+
  scale_x_continuous(breaks=seq(1,len_year,1),labels=levels(mse_df$years),
                     guide = guide_axis(angle = 45))+ xlab("Years")+
  theme_minimal()

```

## 4.3 ANOVA LRT (Likelihood Ratio Test)

Linear regression can be considered a special case of spline regression because spline can be a straight line. In other words, linear regression is a sub-model of spline regression in our case. Therefore, we can use ANOVA LRT to test whether the spline regression outperforms the linear regression. The spline regression has 23 more degrees of freedom than linear regression, and it reduces the residual sum of squares (RSS) from $4590843$ down to $4091156$, which is about $11\%$. $Pr(>Chi) < < 0.001$ may not be meaningful as we have a considerably large amount of data, making the variability small.


```{r anova1, echo=TRUE,results = "asis"}
print_anova(anova(lm_base,ns_base,test="LRT"))
```



## 4.4 Vuong Tests for Model Comparison
We can consider the linear models as a sub model of the spline model, and we can run the nested version of Vuong Test.


```{r vuong, echo=TRUE,eval=FALSE,results = "asis"}
library(nonnest2)
vuongtest(lm_base,ns_base,nested = TRUE)

```
Model 1 <br>
 Class: glm <br>
 Call: glm(formula = as.formula(ns_str), family = gaussian, data = nhanes)<br>

Model 2 
 Class: glm <br>
 Call: glm(formula = as.formula(lm_str), family = gaussian, data = nhanes)<br>

Variance test <br>
  H0: Model 1 and Model 2 are indistinguishable <br>
  H1: Model 1 and Model 2 are distinguishable <br>
    w2 = 0.000,   p = 1<br>

Robust likelihood ratio test of distinguishable models<br>
  H0: Model 2 fits as well as Model 1 <br>
  H1: Model 1 fits better than Model 2 <br>
    LR = 3213.299,   p = 6.32e-09
